Documentation of working progress
Thursday, 6th September


Results Thursday 
8 bis 10 Uhr : 
- tried to pull changes - didn't success.
- I fix the spec char in heading. 
- all text from manuskript and landeskunde is printed, no parts missing anymore


Only left of today:
cannot connect to github 

Goals for tomorrow: 
start with "meineBand"


-----------------------------------------------------------------

Documentation of working progress
Wednesday, 6th September


Results Wednesday 
8 bis 10 Uhr : 
- habe Rubrik "Manuskript" gecrawlt ✓

For finishing crawler: 
- meta.csv Titel tragen Sonderzeichen 
- manche Manuskripte sind leer, andere nur Anfang abgedruckt(Happy Birthday, Was machst du denn hier?). 
  Manuskipte auf Vollständigkeit überprüfen
- mit "meineBand" anfagen  


goal: 
- auch wenn ich Freizeit möchte, es würde mich auch freuen, wenn ich das Ziel von 2 Webseiten erreichen würde.  
- wie weit kommt ich mit dem crawler "meine Band"? - habe noch nicht angefangen, Crawler für "manuskripte" geschrieben. 
- welche Ziele könnte es die nächsten Tage geben? "Manuskripte" fertig machen, meineBand anfagen 




-------------------------------------------------------------

Documentation of working progress
Tuesday, 5th September

Feedback: 
- einarbeitungszeit bis man weiß, wo man steht, war über einen recht langen Zeitraum unklar
- (noch) keine starken hardskills, deshalb: wer hat gute Softskills? 
  Softskills: Fragen stellen, Wissbegierig, nett
- auch: Ziel evaluiert. 1,5 Webseiten. Wurde (mit guten Willen) erreicht

aber ich weiß nicht, welche weiteren Punkte es gibt. 
- Nicos Weg: glaube ich fertig
- biberCrawler: AutorInnen rausfiltern
- 
toDO: 
- herausfinden Nicos Weg fertig? Leider nochmal laufen lassen, 
- ist biberCrawler fertig wird alles geprinted? Leider nochmal laufen lassen
- jetzt: für welche Artikel gibt es AutorInnen, für welche keine? 
         stehen die AutorInnen immer in der ersten Zeile?
- if p empty, wird artikel dann übergangen? 

- Artikel: nach subtitle IIII
          als subtitle
          keine* AutorIn 

          AutorInnen: 
          Von Özben Önal, Mitarbeit: Aleksandra Tulej
          von Dennis Miskić
          Von Banan Sakbani, Fotos: Zoe Opratko
          Von Nada El-Azar-Chekh, Fotos: Atila Vadoc 
          Kolumne von Ivana Cucujkić-Panić
          Von Dione Azemi, Collage: Zoe Opratko
          Interview: Anja Bachleitner, Foto: Zoe Opratko
          Aus der Kolumne "Der Quoten-Almanci" von Özben Önal
          Von Maria Lovrić -Anušić
          diese Frage stellt sich Sprecher der Grünen Andersrum Wien Emir Dizdarević in einem Gastkommentar.
          von Šemsa Salioski
          Von Emilija Ilić, Illustrationen: Anna Lumaca
          Von: Maria Lovrić-Anušić, Collagen: Zoe Opratko
          Von Helin Kara, Mitarbeit: Nada El-Azar-Chekh und Aleksandra Tulej
          von Janima Nam
          von Amar Rajković
          Interview: Nada El-Azar-Chekh
          Von Sara Mohammadi, Fotos: Lisa Leutner
          Von Celina Dinhopl, Fotos: Zoe Opratko




--------------------------------------------------------------------

Documentation of working progress 
Monday, 4th Septemeber

finished: 
crawl_page_article works and receives the actual href.
crawl_meta works. receives title 
remove iStockphoto. I cannot find the tag which holds the iStockphoto
    ask for help at 1pm 
final run: 
    logs ✓
    title.txt ✓
    learnGerman_article_overview.csv ✓
    processed_learnGerman_files - why is nothing printed ? ?
    learnGerman_meta.csv - why is nothing printed ? ?
    

Questions: 
? printing to csv and processed_files
? remove iStockphoto

Goals: 
- bereich "Nicos Weg" bzw. "Band"
 


ich wäre echt richtig zufrieden, wenn der NicosWeg Crawler funktioniert. 





Goal: 
abschließen zur Übergabe
Übergabe: Dokumentieren, Bestandsaufnahme für ein vollständigen Crawler:
    - was braucht es noch, dass vollständiger Crawler?
abschließen BiberCrawler: was fehlt?
bestandsaufnahme NicosWegCrawler





------------------------------------------------------------------------------------------------


Documentation of working progress 
Sunday, 3rd Septemeber

Question: 
- where am I in the code? What works, what is not quiet working, 
  what is still to code?
    Crawl() works. Result: receive 77 links. These links lead to articles
    crawl_article_page. Soll: link zu Landeskunde article
                         Ist: - ein Teil des Links wird abgedruckt. Need to debug with Denise


---------------------------------------------------------------------------------------------------


Documentation of working progress
Friday, 1st September

steps for morning: 
learnGermanCrawler - nicos weg
1. 2 metadata file erstellen ✓
2. variablen für meta data nennen,
   und Inhalt f. Variablen suchen ✓
3. Variablen an add_to_MetaFile übergeben

Questions: 

- full title: Begrüßungen auf Deutsch | Landeskunde | Hallo! | DW Deutsch Lernen . habe alles ab "| Landeskunde" abgeschnitten
- learnGerman data geben lassen

B u g   Q u e s t i o n s

- why is the link in crawl_page == None?
- wieso wird nicht auf csv file abgedruckt?


------------------------------------------------------------------------------------------------------


Documentation of working progress
Thursday 31. August


Questions:
file bibermeta.csv: why is Bereich printed and not fileName?
file biber_article_overview: why is nothing printed there?
file processed_files: why is nothing printed there?

finished today:
- csv mit flutercsv vergleichen, ändern, dass es flutercsv gleich ist
- zweites meta file: title, url, bereich. But doesnt work 


goals for today:
- ausprobieren: funktioniert die Methode für Daten zu meta file hinzufügen so, dass das alle Meta data übergeben wird? Fast
- ausprobieren: funktioniert die Methode für zweites meta file so wie ich möchte? Nein



--------------------------------------------------------------------------------------------------------------

Docuemntation of working progress
Wednesday, 30. August 



--------Pausa ----------

--------------------------------------------------------------------------------------------------------------

Documentation of working progress
Tuesday, 29 August

finsihed today:
- what happens if I omit all div tags? Info might not be caught. 
 Solution: only omit div tags of <div, class = media media-element container media-default>
- ran code on old articles. Result is perfectly fine                                                                                         
- add files to logs/ processed_files 
- meta file vervollständigen (15min)

gaols for today: 
things to do:
- Liste von AutorInnen
- einzige Schwachstelle. Manchmal sind tags nicht da, führt zu Fehlermeldung. Muss ich noch beheben. Alle 600 Artikel etwa 
- feedback holen. Was war gut, was hätten sie sich anders gewünscht? 
- wie geht es weiter, noch eine Webseite? Habe ich eine Deadline für 5. September?

Questions for meeting: 
- where headers? 
- ask for feedback 

--------------------------------------------------------------------------------------------------------------

Documentation of working progress 
Monday, 28. August

finished today:
- debugging method for extracting text and printing. 
  Error not found, asked for help and provided code and explanation
- call with Bendedikt for fixing duplicated text. Fixed as we get text from children of "field-item odd" ✓


Zwischenstand:
- alle Texte werden gedruckt, keine Duplikate. Immer AutorInnen (da kein klarer Tag) sowie manchmal Bildunterschriften enthalten.
-  Foto  u. Autor wird abgedruckt. Ganz normaler Text, ohne speziellen Tag name (3min mit Omar Kaissi)
- Bildunterschrif wird abgedruckt (Mit Copyright symbol) (gemma grillen)
- Herr Thür wird nicht abgedruckt 
- Optimal vorbereitet - Bildunterschrif wird nicht abgedruckt ✓
- SREBRNICA  Bildunterschrif wird nicht abgedruckt, Autor schon
- stelldich nicht so an: Autor wird abgedruckt 
- vonselbstgesponnen ... Autor wird abgedruckt

things to do:
- was passiert wenn ich allg divs ausklammere?
- Liste von AutorInnen
- meta file vervollständigen
- code auch für alte Webseiten ausprobieren
------------------------------------------
ich glaube dann bin ich wirklich fertig. 

---------------------------------------------------------------------------------------------

Documentation of working progress
Sunday, 27. August

finished today:
debugging method for printing metaData to csv file. 
Error found.
debugging missing white spaces, error found. 

started today:
delete duplicates:
rewrite crawling method so that there are no duplicates


gaols for tomorrow:
- finsih rewriting crawling method
- add data to logs.txt and processed_files.txt (10min) 
- check out html of new website



----------------------------------------------------------------------------------------------

Documentation of working progress
Saturday, 26. August

finished today:
make code run again  ✓
add fileName to meta.csv  ✓
allow Umlaute in file names ✓
add "bereich" to meta data  ✓
change code so that metadata is contained once ✓

started today:
inspect bibermeta.csv: Compare meta data file and meta data analog with two examples 
                       hand in meta data 



goals for I don't know when: 
- add data to logs.txt and processed_files.txt (10min) 
- Formulate question detailedly for add text to files and ask for support on Monday ✓




ab 17 Uhr: meine eigene Zeit nur für mich 


-----------------------------------------------------------------------------------------

Documentation of working progress
Friday, 25. August 

finished today: 
rebuild code of yesterdays progress - changes weren't safed 
replacing special characters
print text to files

started today:
debugging method of printing to file. Duplicate sentences printed. 

goal for next few days: 
- add "bereich" to meta data 
- add line breaks to .txt files?
- what crawling info to include in code? (ask Purita)
- enlarge range for websites
- add fileName to metaData.csv
- allow Umlaute in fileName


------------------------------------------------------------------------------
Documentation of working progress
Thursday, 24. August 

finished so far: 
all definitions of which the crawler must consists to work

finished today:
def get_each_URL(url_page)
def get_page

started today: 
merging all definitions to one "crawler code" 
fixing unexpected bugs

goal for the next few days: 
for tomorrow morning: merge code snippets for biber crawler. If any unexpected bugs, fix them. Hand in biberCrawler
tomorrow afternoon: start new website, view html code
next days: draft of crawler new website, start coding on receiving text/meta data 

----------------------------------------------------------------------------

Documentation of past working progress 
11. Aug - 23.Aug 

I have worked 28h yet. 
Estimated content of my working hours: 
10h for understanding structure html of website, draft of crawler code,  watching tutorial on html & beautifulsoup
10h for reading documentation of beautifulsoup, writing the methods 
8h for reading documentation again, debugging 

As I am now familiar with beautifulsoup and "real world" html source code of a website, 
I don't expect needing as much time for the next website as I did for the biberCrawler


