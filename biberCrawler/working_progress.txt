Documentation of working progress
Sunday, 27. August

finished today:
debugging method for printing metaData to csv file. 
Error not found. Asked for help on GitHub





Documentation of working progress
Saturday, 26. August

finished today:
make code run again  ✓
add fileName to meta.csv  ✓
allow Umlaute in file names ✓
add "bereich" to meta data  ✓
change code so that metadata is contained once ✓

started today:
inspect bibermeta.csv: Compare meta data file and meta data analog with two examples 
                       hand in meta data 



goals for I don't know when: 
- add data to logs.txt and processed_files.txt (10min) 
- ask myself: is everything finished besides txt files? (5min)
- Formulate question detailedly for add text to files and ask for support on Monday ✓
- check out interface of new website. Is there an overview?  (10min)



ab 17 Uhr: meine eigene Zeit nur für mich 




Documentation of working progress
Friday, 25. August 

finished today: 
rebuild code of yesterdays progress - changes weren't safed 
replacing special characters
print text to files

started today:
debugging method of printing to file. Duplicate sentences printed. 

goal for next few days: 
- add "bereich" to meta data 
- add line breaks to .txt files?
- what crawling info to include in code? (ask Purita)
- enlarge range for websites
- add fileName to metaData.csv
- allow Umlaute in fileName


------------------------------------------------------------------------------
Documentation of working progress
Thursday, 24. August 

finished so far: 
all definitions of which the crawler must consists to work

finished today:
def get_each_URL(url_page)
def get_page

started today: 
merging all definitions to one "crawler code" 
fixing unexpected bugs

goal for the next few days: 
for tomorrow morning: merge code snippets for biber crawler. If any unexpected bugs, fix them. Hand in biberCrawler
tomorrow afternoon: start new website, view html code
next days: draft of crawler new website, start coding on receiving text/meta data 

----------------------------------------------------------------------------

Documentation of past working progress 
11. Aug - 23.Aug 

I have worked 28h yet. 
Estimated content of my working hours: 
10h for understanding structure html of website, draft of crawler code,  watching tutorial on html & beautifulsoup
10h for reading documentation of beautifulsoup, writing the methods 
8h for reading documentation again, debugging 

As I am now familiar with beautifulsoup and "real world" html source code of a website, 
I don't expect needing as much time for the next website as I did for the biberCrawler


