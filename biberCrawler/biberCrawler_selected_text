from bs4 import BeautifulSoup
import requests
import codecs
import re

basePath = "biberCrawler"
metaFileName = basePath + "/bibermeta.csv"
# Variables which have the same value for all articles
biberLizenz = 'unknown'
encoding = "utf-8"
author = 'dasBiber'
org = 'dasBiber'# 
orgLink = 'https://www.dasbiber.at/'
logs = 'logs.txt'  # Define logs file path

r = requests.get("https://www.dasbiber.at/content/optimal-vorbereitet-auf-die-karriere-der-gesundheits-und-krankenpflege")
data = r.text
soup = BeautifulSoup(data, features="html.parser")

# Method to append meta data to bibermeta.csv
def addToMetaFile(fileName, url, title, author, org, orgLink):
    with codecs.open(metaFileName, 'a', encoding) as f:
        f.write(f'{fileName}\t{title}\t{url}\t\t{biberLizenz}\t{author}\t\t{org}\t{orgLink}\n')
        f.close()

    logIt(str("added to Meta - " + title))

# Function to log URLs
def logIt(text):
    with codecs.open(logs, 'a', encoding) as f:
        f.write(text+ "\n")
        f.close()
    print(text)

# Crawling method
def crawl_page():
     r = requests.get('https://www.dasbiber.at/content/optimal-vorbereitet-auf-die-karriere-der-gesundheits-und-krankenpflege')
     data = r.text
     soup = BeautifulSoup(data, features="html.parser")
     
     meta_title = soup.title
     meta_title = meta_title.string 
     meta_title = meta_title[:-11]
     print(meta_title)
     fileName = meta_title.replace(" ", "") + '.txt'
     print(fileName)
     
     baseUrl = 'https://www.dasbiber.at/content/'
     url = (soup.find('link', rel=re.compile('canonical'))['href']) 
     
     logIt(url)
     addToMetaFile(fileName, url, meta_title, author, org, orgLink)


# Ziel der Funktion: text filtern. Bildunterschriften (welche in div class sind) sowie "&nsbp" sowie "*BEZAHLTE ANZEIGE*" nicht drucken. 
# Coding approach:  über alle tags iterieren und prüfen, dass sie nicht eine div class sind. Wenn sie keine div class sind,text abdrucken, solange er nicht 
# "&nsbp" bzw. "*BEZAHLTE ANZEIGE*" ist. 
# Zeile 65 funktioniert nicht, Fehler muss dort behoben werden, weiß nicht wo das Problem ist. 
def crawlSelectedText(soup):
    text = ""
    parent = soup.find("div", {"class":"node-content"}) #find all tags, safe them in variable 
    print(parent)
   
    for child in parent: 
        if (child.name != "div" in child.get("class", [])): #habe diese Zeile aus flutercrawler (line 68) kopiert. Wieso funktioniert es bei mir nicht?
            txt = child.get_text().strip()
            if (txt != "&nbsp" or "*BEZAHLTE ANZEIGE*"):
                text += txt
                print(text)
        else: 
            continue     
        return text



# Calling the crawl_page function
#crawl_page()
crawlSelectedText(soup)


